# Invar-RAG: Invariant LLM-aligned Retrieval for Better Generation

- **Motivation**
    
    这篇文章的核心问题是解决现有**基于检索增强生成（RAG，Retrieval-Augmented Generation）方法的局限性，尤其在处理生成高准确性、低幻觉率**的答案时存在的挑战。
    
    传统RAG方法利用外部检索模型辅助生成，但通常依赖于深度学习驱动的静态检索机制，缺乏对复杂语义关系的精准捕捉，且在生成时容易受到检索阶段噪声和不一致性的影响。
    
    **本论文提出了一个两阶段微调框架Invar-RAG**，通过优化检索和生成模型的协同机制，显著提升了RAG系统的检索性能和生成质量。
    
    **现有方法的问题**
    
    1.	**特征局部性（Feature Locality）**：
    
    •传统方法倾向于基于文档标识符（DocID）或文档摘要进行检索，这种“局部化”的输入不能全面利用文档的全局信息。
    
    •直接使用完整文档输入会导致模型计算开销过高且不现实。
    
    2.	**检索方差（Retrieval Variance）**：
    
    •检索模型生成的候选文档在不同的上下文或查询重写情况下表现出较大的性能波动。
    
    •检索到的内容可能包括冗余或低相关的信息，从而对生成阶段造成干扰。
    
    3.	**检索与生成模块的架构隔离**：
    
    •检索和生成阶段的独立优化导致两者难以充分协同，无法实现统一的性能提升。
    
- Pipeline
    
    ![image.png](Invar-RAG%20Invariant%20LLM-aligned%20Retrieval%20for%20Bett%2015dcd9a0c43a8038ab69fec551800b82/image.png)
    
    **Pipeline 工作流程总结**
    
    1.**输入阶段**：
    
    •用户输入查询后，模型对其进行向量化表示，同时对输入查询进行重写和上下文窗口调整，生成多样化的检索条件。
    
    2.**检索阶段**：
    
    •检索模块通过 LLM 对齐检索策略提取高相关文档，利用不变性损失优化检索鲁棒性，最终生成按相关性排序的候选文档。
    
    3.**生成阶段**：
    
    •检索到的高相关文档被整合为上下文输入，形成扩展 Prompt，输入到生成模型中。
    
    •生成模型结合上下文信息和用户查询生成高质量答案，同时保留内置知识用于补充。
    
    4.**输出阶段**：
    
    •模型输出的最终答案具有较高的准确性，避免了传统 RAG 系统中幻觉和噪声的影响。
    
    通过检索和生成的两阶段协同微调，Invar-RAG 有效解决了特征局部性和检索方差问题，实现了高效、鲁棒的检索和生成性能。
    
- Train
    
    **检索阶段（Retrieval Stage）**
    
    1.**输入表示学习**： LoRA微调 
    
    将DPR 中的基础模型（通常为 BERT 或 RoBERTa）替换为 **LLaMA**
    
    •检索阶段基于双编码器架构（DPR），分别对查询和文档进行高维向量化表示。模型使用 MiniLM 作为初始编码器，将查询和文档映射到稠密的语义空间中。
    
    2.**语义对齐优化**：
    
    •模型使用 KL 散度损失（KL-divergence Loss）对齐查询和文档的语义表示，使查询-文档对在 LLM 的表示空间中能够更好地匹配。
    
    3.	**不变性损失（Invariance Loss）**：
    
    在优化过程中加入不变性损失（Invariance Loss），通过识别不变模式（Invariant Pattern）和变动模式（Variant Pattern），减少模型对低相关性或噪声文档的依赖，增强鲁棒性。
    
    模型利用 LSR 分数（LM-Supervised Retrieval Score）评估检索文档的重要性，区分不变模式（Invariant Pattern）和变动模式（Variant Pattern）
    
    •**不变模式**：对生成结果贡献最大的文档，模型重点优化。
    
    •**变动模式**：噪声文档或低相关文档，模型逐步降低其影响。
    
    •最终，模型通过不变性损失函数（Invariance Loss）进一步优化检索阶段的鲁棒性，减少由输入变动引起的性能波动。
    
    2.	**生成模型微调**：**LLaMA-2**
    
    •**目标**：优化生成模型在基于检索结果生成高质量答案时的**上下文整合能力**。
    
    •**方法**：
    
    •将检索到的前 k 个相关文档作为上下文信息，结合用户查询构造训练样本。
    
    •使用标准的下一个 Token 预测损失（NLL），优化生成模型的预测能力。
    
    •通过在不同任务上的微调，使生成模型能够在检索内容不足时动态利用其参数化知识生成答案，同时减少幻觉现象的发生。
    
    **生成阶段（Generation Stage）**
    
    1.	**上下文整合**：
    
    •在生成阶段，检索到的相关文档作为上下文信息被整合到用户查询中，形成扩展 Prompt。扩展 Prompt 的设计旨在最大程度利用检索内容，同时保留用户问题的核心语义。
    
    例如：Prompt:
    
    Refer to the retrieved documents below and answer the question. Explain your reasoning step by step.
    
    Documents: [Top-5 relevant documents]
    
    Question: [User query]
    
    2.	**生成模型微调**：
    
    对检索到的每个文档片段创建独立的训练样本（文档 + 查询 + 答案），以增加模型的上下文整合能力。
    
    •使用标准的下一个 Token 预测损失（Negative Log-Likelihood Loss, NLL）优化生成模型，最大化生成正确答案的概率。
    
    3.	**生成策略优化**：
    
    •当检索文档未能提供准确答案时，模型能够利用其**内部参数化知识**生成合理结果。这一机制减少了幻觉现象（Hallucination）的发生。
    
    •在生成答案时，模型对检索内容和内置知识进行动态权衡，确保生成内容的准确性和一致性。
    
- Eval
    
    ![image.png](Invar-RAG%20Invariant%20LLM-aligned%20Retrieval%20for%20Bett%2015dcd9a0c43a8038ab69fec551800b82/image%201.png)
    
    •**检索指标**：
    
    •使用 Acc@5 和 Acc@20 衡量检索模块的文档相关性召回能力。
    
    •**生成指标**：
    
    •使用 Exact Match（EM）判断生成答案的准确性。