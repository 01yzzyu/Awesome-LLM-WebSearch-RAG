# Awesome-LLM-Websearch-RAG [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

[![MIT License](https://img.shields.io/badge/license-MIT-green.svg)](https://opensource.org/licenses/MIT)

- ❤ We provide a comprehensive list of LLM-Websearch-RAG, focus on developing and optimizing web-scale Retrieval-Augmented Generation (RAG) systems tailored for understanding up-to-date vision knowledge.


## Table of Content

- [Awesome-Websearch-RAG](#Awesome-LLM-Websearch-RAG)
  - [RAG Survey](#RAG-Survey)
  - [Enhanced Retrieval](#Enhanced-Retrieval)
  - [Websearch RAG](#Websearch-RAG)

## RAG-Survey


|  Date |       Keywords       |    Institute (first)   | Paper                                                                                                                                                                               | Publication | Code | Project | 
| :-----: | :------------------: | :--------------: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------: | :---------:| :---------: 
| 2024-06-17 | Survey | HK PolyU | [A Survey on RAG Meets LLMs: Towards Retrieval-Augmented Large Language Models](https://arxiv.org/abs/2405.06211) | KDD 2024 |  [Code](https://advanced-recommender-systems.github.io/RAG-Meets-LLMs/) | [Project](https://advanced-recommender-systems.github.io/RAG-Meets-LLMs/) | 

## Enhanced-Retrieval
|  Date |       Keywords       |    Institute (first)   | Paper                                                                                                                                                                               | Publication | Code | Project |  Others | 
| :-----: | :------------------: | :--------------: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------: | :---------:| :---------: | :---------: 
| 2024-10-28 | SubgraphRAG | Georgia Tech | [Simple is Effective: The Roles of Graphs and Large Language Models in Knowledge-Graph-Based Retrieval-Augmented Generation](https://arxiv.org/abs/2410.20724) | Arxiv 2024  |  [Code](https://github.com/Graph-COM/SubgraphRAG) |  |  | 
| 2024-05-26 | RAGraph | PKU | [RAGraph: A General Retrieval-Augmented Graph Learning Framework](https://arxiv.org/abs/2410.23855) | NIPS 2024 | [Code](https://github.com/Artessay/RAGraph/)  |  |   | | 
| 2024-06-03 | RGNN-Ret | HKUST | [Graph Neural Network Enhanced Retrieval for Question Answering of LLMs](https://arxiv.org/abs/2406.06572) | Arxiv 2024  |  |   | | 
| 2024-05-26 | GRAG | Emory | [GRAG: Graph Retrieval-Augmented Generation](https://arxiv.org/abs/2405.16506) | Arxiv 2024 |   |  |   | | 





## Websearch-RAG

|  Date |       Keywords       |    Institute (first)   | Paper                                                                                                                                                                               | Publication | Code | Project |  Others | 
| :-----: | :------------------: | :--------------: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------: | :---------:| :---------: | :---------:
| 2024-11-30 | Video-RAG | Xiamen U | [Video-RAG: Visually-aligned Retrieval-Augmented Long Video Comprehension](https://arxiv.org/abs/2411.13093) | Arxiv 2024 |  [Code](https://github.com/Leon1207/Video-RAG-master) | ｜ ｜
| 2024-11-29 | 01.AI | HKUST | [Zero-Indexing Internet Search Augmented Generation for Large Language Models](https://arxiv.org/abs/2411.19478) | Arxiv 2024 |  [Code](https://www.01.ai/) | [Project](https://www.01.ai/) | [View](https://github.com/01yzzyu/Awesome-LLM-Websearch-RAG/blob/main/assets/01.AI/01/Zero-Indexing%20Internet%20Search%20Augmented%20Generation%2015ccd9a0c43a806fb52bc706798545a8.md) |
| 2024-11-29 | Auto-RAG | ICT/CAS | [Auto-RAG: Autonomous Retrieval-Augmented Generation for Large Language Models](https://arxiv.org/abs/2411.19443) | Arxiv 2024 |  [Code](https://github.com/ictnlp/Repository-for-the-forthcoming-work) | | [View](https://github.com/01yzzyu/Websearch-RAG/blob/main/assets/SearchLVLMs/SearchLVLMs.md) |
| 2024-11-11 | Invar-RAG | CityU HK | [Invar-RAG: Invariant LLM-aligned Retrieval for Better Generation](https://arxiv.org/abs/2411.07021) | Arxiv 2024 |    |   | [View](https://github.com/01yzzyu/Awesome-LLM-Websearch-RAG/blob/main/assets/invar/Invar-RAG%20Invariant%20LLM-aligned%20Retrieval%20for%20Bett%2015dcd9a0c43a8038ab69fec551800b82.md) |
| 2024-10-28 | VSA | MMLab | [Vision Search Assistant: Empower Vision-Language Models as Multimodal Search Engines](https://arxiv.org/abs/2410.21220) | Arxiv 2024 |  [Code](https://github.com/cnzzx/VSA) | [Project](https://cnzzx.github.io/VSA/)| [View](https://github.com/01yzzyu/Websearch-RAG/blob/main/assets/SearchLVLMs/SearchLVLMs.md) |
| 2024-10-9 | AutoFeedback | NUDT | [AutoFeedback: An LLM-based Framework for Efficient and Accurate API Request Generation](https://arxiv.org/abs/2410.06943) | Arxiv 2024 |  [Code](https://github.com/NeverMoreLCH/SearchLVLMs1) | [Project](https://nevermorelch.github.io/SearchLVLMs.github.io/1) | [View](https://github.com/01yzzyu/Websearch-RAG/blob/main/assets/SearchLVLMs/SearchLVLMs.md) |
| 2024-10-9 | WeKnow-RAG | Tsinghua | [WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs](https://arxiv.org/abs/2408.07611) | KDD 24 Workshop |  |  | [View](https://github.com/01yzzyu/Awesome-LLM-Websearch-RAG/tree/main/assets/WeKnow-RAG) |
| 2024-05-23 | SearchLVLMs | SHAI Lab | [SearchLVLMs: A Plug-and-Play Framework for Augmenting Large Vision-Language Models by Searching Up-to-Date Internet Knowledge](https://openreview.net/forum?id=leeosk2RAM&referrer=%5Bthe%20profile%20of%20Chuanhao%20Li%5D(%2Fprofile%3Fid%3D~Chuanhao_Li2)) | NeurIPS 2024 poster |  [Code](https://github.com/NeverMoreLCH/SearchLVLMs) | [Project](https://nevermorelch.github.io/SearchLVLMs.github.io/) | [View](https://github.com/01yzzyu/Websearch-RAG/blob/main/assets/SearchLVLMs/SearchLVLMs.md) |
| 2024-03-31 | RQ-RAG | HKUST | [RQ-RAG: Learning to Refine Queries for Retrieval Augmented Generation](https://arxiv.org/abs/2404.00610) | COLM 2024 |  [Code](https://github.com/chanchimin/RQ-RAG) | | [View](https://github.com/01yzzyu/Websearch-RAG/blob/main/assets/SearchLVLMs/SearchLVLMs.md) |
| 2024-03-15 | DRAGIN | Tsinghua | [DRAGIN: Dynamic Retrieval Augmented Generation based on the Information Needs of Large Language Models](https://arxiv.org/abs/2403.10081) | ACL 2024 |  [Code](https://github.com/oneal2000/DRAGIN/tree/main) |  | [View](https://github.com/01yzzyu/Awesome-LLM-Websearch-RAG/blob/main/assets/dragin/DRAGIN%20Dynamic%20Retrieval%20Augmented%20Generation%20base%2015dcd9a0c43a80a3b92fddfd32d1a036.md) |
| 2023-12-18 | CLOVA | PKU | [CLOVA: A Closed-Loop Visual Assistant with Tool Usage and Update](https://arxiv.org/abs/2312.10908) | CVPR 2024 |  [Code](https://github.com/clova-tool/CLOVA-tool) | [Project](https://clova-tool.github.io/) | [View](https://nevermorelch.github.io/SearchLVLMs.github.io/) |
| 2023-10-17 | Self-RAG | UW | [Self-RAG: Learning to Retrieve, Generate and Critique through Self-Reflections](https://arxiv.org/abs/2312.10908) | ICLR 2024 oral |  [Code](https://github.com/AkariAsai/self-rag) | [Project](https://selfrag.github.io/) | [View](https://nevermorelch.github.io/SearchLVLMs.github.io/) |
| 2023-04-19 | Chameleon | UCLA | [Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models](https://openreview.net/forum?id=leeosk2RAM&referrer=%5Bthe%20profile%20of%20Chuanhao%20Li%5D(%2Fprofile%3Fid%3D~Chuanhao_Li2)) | NeurIPS 2023 poster |  [Code](https://github.com/lupantech/chameleon-llm) | [Project](https://chameleon-llm.github.io/) | [View](https://github.com/01yzzyu/Websearch-RAG/blob/main/assets/SearchLVLMs/SearchLVLMs.md) |
| 2023-03-20 | MM-REACT | Microsoft | [MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action](https://arxiv.org/abs/2303.11381) | CVPR 2023 |  [Code](https://github.com/microsoft/MM-REACT) | [Project](https://multimodal-react.github.io/) | [View](https://github.com/01yzzyu/Websearch-RAG/blob/main/assets/SearchLVLMs/SearchLVLMs.md) |
| 2023-03-19 | ViperGPT | ColumbiaU | [ViperGPT: Visual Inference via Python Execution for Reasoning](https://arxiv.org/abs/2303.08128) | CVPR 2023 |  [Code](https://github.com/cvlab-columbia/viper) | [Project](https://viper.cs.columbia.edu/) | [View](https://github.com/01yzzyu/Websearch-RAG/blob/main/assets/SearchLVLMs/SearchLVLMs.md) |
| 2023-03-08 | Visual chatgpt | Microsoft | [Visual chatgpt: Talking, drawing and editing with visual foundation models](https://arxiv.org/abs/2303.04671) | Arxiv 2023 |  [Code](https://github.com/chenfei-wu/TaskMatrix) | [Project](https://github.com/chenfei-wu/TaskMatrix) | [View](https://github.com/01yzzyu/Websearch-RAG/blob/main/assets/SearchLVLMs/SearchLVLMs.md) |

## Benchmark

|  Date |       Keywords       |    Institute (first)   | Paper                                                                                                                                                                               | Publication | Code | Project |  Others | 
| :-----: | :------------------: | :--------------: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------: | :---------:| :---------: | :---------:
| 2024-11-29 | TQA-Bench | HKUST | [TQA-Bench: Evaluating LLMs for Multi-Table Question Answering with Scalable Context and Symbolic Extension](https://arxiv.org/abs/2411.19504) | Arxiv 2024 |  [Code](https://github.com/Relaxed-System-Lab/TQA-Bench) | [Project](https://github.com/Relaxed-System-Lab/TQA-Bench) | |
| 2024-10-02 | MMQA|  | [MMQA: Evaluating LLMs with Multi-Table Multi-Hop Complex Questions](https://openreview.net/forum?id=GGlpykXDCa) | ICLR 2025 Oral | | | |
| 2024-10-07 | TableRAG | NTU(Taiwan) | [TableRAG: Million-Token Table Understanding with Language Models](https://arxiv.org/abs/2410.04739) | NIPS 2024 | [Code](https://github.com/google-research/google-research/tree/master/encyclopedic_vqa) |  |  |
| 2023-06-15 | Encyclopedic VQA | Google | [Encyclopedic VQA: Visual questions about detailed properties of fine-grained categories](https://arxiv.org/abs/2411.19504) | ICCV 2023 |  [Code](https://github.com/google-research/google-research/tree/master/encyclopedic_vqa) |  |  |



